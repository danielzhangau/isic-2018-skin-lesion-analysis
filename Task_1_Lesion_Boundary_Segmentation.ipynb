{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 1: Lesion Boundary Segmentation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leigh-johnson/isic-2018-skin-lesion-analysis/blob/master/Task_1_Lesion_Boundary_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XDd44HXIbhvX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Task 1: Lesion Boundary Segmentation\n",
        "\n",
        "## Goal\n",
        "\n",
        "Submit automated predictions of lesion segmentation boundaries within dermoscopic images.\n",
        "\n",
        "![Task 1 example segmentation boundaries](https://challenge2018.isic-archive.com/wp-content/uploads/2018/04/task1.png)\n",
        "\n",
        "## Data\n",
        "### Input Data\n",
        "\n",
        "The input data consists of dermoscopic lesion images in JPEG format.\n",
        "\n",
        "All lesion images are named using the scheme ISIC_<image_id>.jpg, where <image_id> is a 7-digit unique identifier. EXIF tags in the images have been removed; any remaining EXIF tags should not be relied upon to provide accurate metadata.\n",
        "\n",
        "The lesion images were acquired with a variety of [dermatoscope types](https://dermoscopedia.org/Principles_of_dermoscopy), from all anatomic sites (excluding mucosa and nails), from a historical sample of patients presented for skin cancer screening, from several different institutions. Every lesion image contains exactly one primary lesion; other fiducial markers, smaller secondary lesions, or other pigmented regions may be neglected.\n",
        "\n",
        "The distribution of disease states represent a modified “real world” setting whereby there are more benign lesions than malignant lesions, but an over-representation of malignancies.\n",
        "\n",
        "### Response Data\n",
        "\n",
        "The response data consists binary mask images in PNG format, indicating the location of the primary skin lesion within each input lesion image.\n",
        "\n",
        "Mask images are named using the scheme ISIC_<image_id>_segmentation.png, where <image_id> matches the corresponding lesion image for the mask.\n",
        "\n",
        "Mask images must have the exact same dimensions as their corresponding lesion image. Mask images are encoded as single-channel (grayscale) 8-bit PNGs (to provide lossless compression), where each pixel is either:\n",
        "\n",
        "* 0: representing the background of the image, or areas outside the primary lesion\n",
        "* 255: representing the foreground of the image, or areas inside the primary lesion\n",
        "\n",
        "As the primary skin lesion is a single contiguous region, mask images should also contain only a single contiguous foreground region, without any disconnected components or holes. The foreground region may be of any size (including the entire image) and may abut the borders of the image.\n",
        "\n",
        "\n",
        "### Ground Truth Provenance\n",
        "\n",
        "Mask image ground truth (provided for training and used internally for scoring validation and test phases) data were generated using several techniques, but all data were reviewed and curated by practicing dermatologists with expertise in dermoscopy.\n",
        "\n",
        "Ground truth segmentations were generated by either:\n",
        "\n",
        "fully-automated algorithm, reviewed and accepted by a human expert\n",
        "a semi-automated flood-fill algorithm, with parameters chosen by a human expert\n",
        "manual polygon tracing by a human expert\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "### Goal Metric\n",
        "\n",
        "Predicted responses are scored using a threshold [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) metric.\n",
        "\n",
        "To compute this metric:\n",
        "\n",
        "* For each image, a pixel-wise comparison of each predicted segmentation with the corresponding ground truth segmentation is made using the Jaccard index.\n",
        "* The final score for each image is computed as a threshold of the Jaccard according to the following:\n",
        "  * score = 0, if the Jaccard index is less than 0.65\n",
        "  * score = the Jaccard index value, otherwise\n",
        "* The mean of all per-image scores is taken as the final metric value for the entire dataset\n",
        "\n",
        "### Rationale\n",
        "The choice of threshold Jaccard index metric is based on a previously published analysis which demonstrated using the Jaccard directly as a measure of performance does not accurately reflect the number of images in which automated segmentation fails, or falls outside expert interobserver variability (i.e. the raw Jaccard is overly optimistic). The number of images in which automated segmentation fails is a direct measure of the amount of labor required to correct an algorithm.\n",
        "\n",
        "In order to determine the threshold, the lowest Jaccard agreement between 3 independent expert annotators was measured on a subset of 100 images. This empirically measured value (~0.74) is the basis for the 0.65 value threshold (with additional error tolerance), which indicates segmentation failure on an image.\n",
        "\n",
        "### Other Metrics\n",
        "Participants will be ranked and awards granted based only on the Threshold Jaccard index metric. However, for scientific completeness, predicted responses will also have the following metrics computed on a pixel-wise basis (comparing prediction vs. ground truth) for each image:\n",
        "\n",
        "* sensitivity\n",
        "specificity\n",
        "accuracy\n",
        "raw Jaccard index\n",
        "Dice coefficient"
      ]
    },
    {
      "metadata": {
        "id": "GEmvGe1ibyAz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-iwH1DkEcam",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Approach\n",
        "\n",
        "\n",
        "* [Mask R-CNN for Object Detection and Segmentation](https://github.com/matterport/Mask_RCNN)\n"
      ]
    },
    {
      "metadata": {
        "id": "21Vz50wu8J_H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "Data was extracted from the “ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection” grand challenge datasets [1][2].\n",
        "\n",
        "[1] Noel C. F. Codella, David Gutman, M. Emre Celebi, Brian Helba, Michael A. Marchetti, Stephen W. Dusza, Aadi Kalloo, Konstantinos Liopyris, Nabin Mishra, Harald Kittler, Allan Halpern: “Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC)”, 2017; arXiv:1710.05006.\n",
        "\n",
        "[2] Tschandl, P., Rosendahl, C. & Kittler, H. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Sci. Data 5, 180161 doi:10.1038/sdata.2018.161 (2018).\n",
        "\n",
        "@misc{matterport_maskrcnn_2017,\n",
        "  title={Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow},\n",
        "  author={Waleed Abdulla},\n",
        "  year={2017},\n",
        "  publisher={Github},\n",
        "  journal={GitHub repository},\n",
        "  howpublished={\\url{https://github.com/matterport/Mask_RCNN}},\n",
        "}\n"
      ]
    },
    {
      "metadata": {
        "id": "6EV9mC15Etyi",
        "colab_type": "code",
        "outputId": "498d4498-aa18-49e7-deb1-5fa90954b89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone git@github.com:matterport/Mask_RCNN.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "Host key verification failed.\r\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}